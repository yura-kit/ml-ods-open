{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Open Machine Learning Course\n",
    "<center>\n",
    "Author: Yury Kashnitsky, Data Scientist at Mail.Ru Group\n",
    "\n",
    "This material is subject to the terms and conditions of the license [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Free use is permitted for any non-comercial purpose with an obligatory indication of the names of the authors and of the source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Assignment #6. Part 1\n",
    "### <center> Beating benchmarks in \"Catch Me If You Can: Intruder Detection through Webpage Session Tracking\"\n",
    "    \n",
    "[Competition](https://www.kaggle.com/c/catch-me-if-you-can-intruder-detection-through-webpage-session-tracking2). The task is to beat \"Assignment 6 baseline\".\n",
    "\n",
    "\n",
    "Будем решать задачу идентификации взломщика по его поведению в сети Интернет. Это сложная и интересная задача на стыке анализа данных и поведенческой психологии. В качестве примера, компания Яндекс решает задачу идентификации взломщика почтового ящика по его поведению. В двух словах, взломщик будет себя вести не так, как владелец ящика: он может не удалять сообщения сразу по прочтении, как это делал хозяин, он будет по-другому ставить флажки сообщениям и даже по-своему двигать мышкой. Тогда такого злоумышленника можно идентифицировать и \"выкинуть\" из почтового ящика, предложив хозяину войти по SMS-коду. Этот пилотный проект описан в статье на Хабрахабре. Похожие вещи делаются, например, в Google Analytics и описываются в научных статьях, найти можно многое по фразам \"Traversal Pattern Mining\" и \"Sequential Pattern Mining\".\n",
    "\n",
    "В этом соревновании будем решать похожую задачу: алгоритм будет анализировать последовательность из нескольких веб-сайтов, посещенных подряд одним и тем же человеком, и определять, Элис это или взломщик (кто-то другой).\n",
    "\n",
    "Данные собраны с прокси-серверов Университета Блеза Паскаля. \"A Tool for Classification of Sequential Data\", авторы Giacomo Kahn, Yannick Loiseau и Olivier Raynaud.\n",
    "\n",
    "\n",
    "В обучающей выборке *train_sessions.csv*:\n",
    "\n",
    "Признаки site_i – это индексы посещенных сайтов (расшифровка дана в pickle-файле со словарем *site_dic.pkl*)\n",
    "Признаки time_j – время посещения сайтов site_j\n",
    "Целевой признак target – факт того, что сессия принадлежит Элис (то есть что именно Элис ходила по всем этим сайтам)\n",
    "Задача – сделать прогнозы для сессий в тестовой выборке (*test_sessions.csv*), определить, принадлежат ли они Элис. Не обязательно ограничиваться только предложенной выборкой *train_sessions.csv* – в train.zip даны исходные данные о посещенных пользователями веб-страницах, по которым можно сформировать свою обучающую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import math\n",
    "import operator\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from scipy.sparse import hstack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = ('../../data')\n",
    "train_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_sessions.csv'), index_col='session_id')\n",
    "test_df = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_sessions.csv'), index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'weekday' object has no attribute 'holidays'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1855e04b7e9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mus_cal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mdr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2013-07-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2015-08-01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mus_holidays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mus_cal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholidays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Holiday'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mus_holidays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'weekday' object has no attribute 'holidays'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe688dbf7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import datetime as dt\n",
    "fig, ax = plt.subplots(figsize=(20,10)) \n",
    "\n",
    "start = dt.datetime.strptime('2014-03-17 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "end = dt.datetime.strptime('2014-03-19 01:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "#train_for_check = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_sessions.csv'), index_col='time1', parse_dates=['time1'])\n",
    "#train_for_check = train_for_check[train_for_check['target'] == 1]\n",
    "#y_may = train_for_check[str(start):str(end)]['target']\n",
    "\n",
    "#print(train_df[train_df['target'] == 1].shape)\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "\n",
    "#y_may.plot(style='k.', ax=ax)\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "\n",
    "train_df['start_session_day'] = train_df['time1'].dt.day\n",
    "\n",
    "train_df['start_session_day_of_the_week'] = train_df['time1'].dt.dayofweek\n",
    "train_df[\"start_session_hour\"] = train_df['time1'].dt.hour\n",
    "train_df['start_session_month'] = train_df['time1'].dt.month\n",
    "\n",
    "# platform_genre_sales = train_df.pivot_table(\n",
    "#                         index='start_session_day_of_the_week', \n",
    "#                         columns='start_session_day', \n",
    "#                         values='target', \n",
    "#                         aggfunc=sum).fillna(0).applymap(float)\n",
    "# sns.heatmap(platform_genre_sales, annot=True, fmt=\".1f\", linewidths=.5)\n",
    "\n",
    "import pandas.tseries.holiday as hol\n",
    "us_cal = hol.\n",
    "dr = pd.date_range(start='2013-07-01', end='2015-08-01')\n",
    "us_holidays = us_cal.holidays(start=dr.min(), end=dr.max())\n",
    "train_df['Holiday'] = train_df['time1'].isin(us_holidays)\n",
    "\n",
    "print(train_df['Holiday'].describe())\n",
    "\n",
    "# pivot = train_df.pivot_table(\n",
    "#                         index='start_session_day', \n",
    "#                         columns='Holiday', \n",
    "#                         values='target', \n",
    "#                         aggfunc=sum).fillna(0).applymap(float)\n",
    "\n",
    "\n",
    "# pivot.plot(kind='bar', ax=ax)\n",
    "\n",
    "platform_genre_sales = train_df.pivot_table(\n",
    "                        index='Holiday', \n",
    "                        columns='start_session_day', \n",
    "                        values='target', \n",
    "                        aggfunc=sum).fillna(0).applymap(float)\n",
    "sns.heatmap(platform_genre_sales, annot=True, fmt=\".1f\", linewidths=.5)\n",
    "\n",
    "#plt.plot(y_may[:210])\n",
    "#X_may = train_for_check[str(may_start_time):str(may_end_time)]\n",
    "#times = ['time%s' % i for i in range(2, 11)]\n",
    "#train_for_check[times] = train_for_check[times].apply(pd.to_datetime)\n",
    "\n",
    "#train_for_check[\"pickup_datetime_cutted_to_hour\"] = train_for_check['time1'].values.astype('<M8[h]')\n",
    "#train_for_check[\"pickup_datetime_cutted_to_hour\"] = train_for_check['time1'].dt.hour\n",
    "\n",
    "#train_for_check.plot(x='pickup_datetime_cutted_to_hour', y='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for_check['target'].plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate target feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:05:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>56</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 08:37:23</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2013-01-12 09:07:07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2013-01-12 09:07:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>946</td>\n",
       "      <td>2013-01-12 08:50:13</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:14</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:15</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>784.0</td>\n",
       "      <td>2013-01-12 08:50:16</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>945</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:17</td>\n",
       "      <td>949.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:18</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>945.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:19</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>947</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>948.0</td>\n",
       "      <td>2013-01-12 08:50:20</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>950.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>...</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:21</td>\n",
       "      <td>951.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>946.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>947.0</td>\n",
       "      <td>2013-01-12 08:50:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1               time1  site2               time2  site3  \\\n",
       "session_id                                                                \n",
       "21669          56 2013-01-12 08:05:57   55.0 2013-01-12 08:05:57    NaN   \n",
       "54843          56 2013-01-12 08:37:23   55.0 2013-01-12 08:37:23   56.0   \n",
       "77292         946 2013-01-12 08:50:13  946.0 2013-01-12 08:50:14  951.0   \n",
       "114021        945 2013-01-12 08:50:17  948.0 2013-01-12 08:50:17  949.0   \n",
       "146670        947 2013-01-12 08:50:20  950.0 2013-01-12 08:50:20  948.0   \n",
       "\n",
       "                         time3  site4               time4  site5  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843      2013-01-12 09:07:07   55.0 2013-01-12 09:07:09    NaN   \n",
       "77292      2013-01-12 08:50:15  946.0 2013-01-12 08:50:15  946.0   \n",
       "114021     2013-01-12 08:50:18  948.0 2013-01-12 08:50:18  945.0   \n",
       "146670     2013-01-12 08:50:20  947.0 2013-01-12 08:50:21  950.0   \n",
       "\n",
       "                         time5  ...                 time6  site7  \\\n",
       "session_id                      ...                                \n",
       "21669                      NaT  ...                   NaT    NaN   \n",
       "54843                      NaT  ...                   NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  ...   2013-01-12 08:50:16  948.0   \n",
       "114021     2013-01-12 08:50:18  ...   2013-01-12 08:50:18  947.0   \n",
       "146670     2013-01-12 08:50:21  ...   2013-01-12 08:50:21  946.0   \n",
       "\n",
       "                         time7  site8               time8  site9  \\\n",
       "session_id                                                         \n",
       "21669                      NaT    NaN                 NaT    NaN   \n",
       "54843                      NaT    NaN                 NaT    NaN   \n",
       "77292      2013-01-12 08:50:16  784.0 2013-01-12 08:50:16  949.0   \n",
       "114021     2013-01-12 08:50:19  945.0 2013-01-12 08:50:19  946.0   \n",
       "146670     2013-01-12 08:50:21  951.0 2013-01-12 08:50:22  946.0   \n",
       "\n",
       "                         time9 site10              time10 target  \n",
       "session_id                                                        \n",
       "21669                      NaT    NaN                 NaT      0  \n",
       "54843                      NaT    NaN                 NaT      0  \n",
       "77292      2013-01-12 08:50:17  946.0 2013-01-12 08:50:17      0  \n",
       "114021     2013-01-12 08:50:19  946.0 2013-01-12 08:50:20      0  \n",
       "146670     2013-01-12 08:50:22  947.0 2013-01-12 08:50:22      0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the training and test data sets\n",
    "# train_df = pd.read_csv('../input/train_sessions.csv',\n",
    "#                        index_col='session_id')\n",
    "# test_df = pd.read_csv('../input/test_sessions.csv',\n",
    "#                       index_col='session_id')\n",
    "\n",
    "# Switch time1, ..., time10 columns to datetime type\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# Sort the data by time\n",
    "train_df = train_df.sort_values(by='time1')\n",
    "\n",
    "# Look at the first rows of the training set\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websites total: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42218</th>\n",
       "      <td>www.afdas.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9415</th>\n",
       "      <td>testng.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>www.iforex.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24008</th>\n",
       "      <td>lamuruanimacion.wordpress.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>www.qdabra.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                site\n",
       "42218                  www.afdas.com\n",
       "9415                      testng.org\n",
       "6911                  www.iforex.com\n",
       "24008  lamuruanimacion.wordpress.com\n",
       "2525                  www.qdabra.com"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change site1, ..., site10 columns type to integer and fill NA-values with zeros\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int')\n",
    "test_df[sites] = test_df[sites].fillna(0).astype('int')\n",
    "\n",
    "# Load websites dictionary\n",
    "with open(r\"../../data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# Create dataframe for the dictionary\n",
    "sites_dict = pd.DataFrame(list(site_dict.keys()), index=list(site_dict.values()), columns=['site'])\n",
    "print(u'Websites total:', sites_dict.shape[0])\n",
    "sites_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text'] = train_df[sites].astype(str).apply(lambda x: ' '.join(x), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_sites = full_df[sites]\n",
    "# full_sites.head()# sequence of indices\n",
    "# sites_flatten = full_sites.values.flatten()\n",
    "\n",
    "# # and the matrix we are looking for\n",
    "# full_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0],\n",
    "#                                 sites_flatten,\n",
    "#                                 range(0, sites_flatten.shape[0]  + 10, 10)))[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tiana [17 hours ago]\n",
    "#мне помогло сделать графики когда алиса в интернет ходит (дни, часы и т.д.),  даже не пришлось tf-idf использовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2297.000000\n",
       "mean        1.584676\n",
       "std         1.599186\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         3.000000\n",
       "max         6.000000\n",
       "Name: time1, dtype: float64"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['target']==1].time1.dt.dayofweek.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/sudarikova/NLP_tf-idf/blob/master/tfidf.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text'] = train_df['text'].apply(lambda x: x.replace('0', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Tf-Idf features based on sites. You can use `ngram_range`=(1, 3) and `max_features`=100000 or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "CPU times: user 9.9 s, sys: 28 ms, total: 9.93 s\n",
      "Wall time: 9.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#a = compute_tfidf(corpus)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), max_features=100000)\n",
    "X = vectorizer.fit_transform((train_df['text'].apply(lambda x: x.strip().split(' ')).astype(str)).values)\n",
    "idf = vectorizer.idf_\n",
    "#print( dict(zip(vectorizer.get_feature_names(), idf)))\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_features = ['start_session_hour', 'start_session_day_night', 'start_session_morning', \n",
    "#                 'start_session_day_of_the_week',  'alis_top',\n",
    "#                'start_session_15','start_session_16','start_session_18', \n",
    "#                 'start_session_year_14','start_session_year_13', 'is_weekend']\n",
    "new_features = ['start_session_hour',  \n",
    "                'start_session_day_of_the_week',  'alis_top',\n",
    "               'start_session_15','start_session_16','start_session_18', \n",
    "                'start_session_year_14','start_session_year_13', 'is_weekend']\n",
    "\n",
    "\n",
    "# new_features= ['start_session_hour',  \n",
    "#                 'start_session_day_of_the_week', 'start_session_month', 'alis_top']\n",
    "\n",
    "train_df[\"start_session_year_13\"] = train_df['time1'].dt.year == 13\n",
    "train_df[\"start_session_year_14\"] = train_df['time1'].dt.year == 14\n",
    "\n",
    "train_df[\"start_session_hour\"] = train_df['time1'].dt.hour\n",
    "train_df[\"start_session_day_night\"] = ((train_df['time1'].dt.hour > 20) | (train_df['time1'].dt.hour < 7)).astype(int)\n",
    "train_df[\"start_session_morning\"] = ((train_df['time1'].dt.hour > 5) | (train_df['time1'].dt.hour < 12)).astype(int)\n",
    "\n",
    "train_df['start_session_month'] = train_df['time1'].dt.month\n",
    "train_df['start_session_day_of_the_week'] = train_df['time1'].dt.dayofweek\n",
    "train_df['start_session_15'] = (train_df['time1'].dt.hour == 15).astype(int) \n",
    "train_df['start_session_16'] = (train_df['time1'].dt.hour == 16).astype(int)\n",
    "train_df['start_session_18'] = (train_df['time1'].dt.hour == 18).astype(int)\n",
    "train_df[\"is_weekend\"] = train_df['time1'].dt.weekday.isin([5,6])*1 #индикатор выходных\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = train_df[(train_df['target'] == 1)][sites]\n",
    "\n",
    "words['text'] = words[sites].astype(str).apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "all_words_list = [word for word in words['text'].apply(lambda x: x.split(' '))]\n",
    "import numpy as np\n",
    "flatten = list(np.array(all_words_list).flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df[train_df['start_session_morning'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "alis_most_freq_sites = Counter(flatten)#.most_common(100)\n",
    "\n",
    "#print(alis_most_freq_sites.most_common(10))\n",
    "alis_top_sites  = sorted(alis_most_freq_sites, key=alis_most_freq_sites.get, reverse=True)[:100]\n",
    "\n",
    "#print(alis_top_sites)\n",
    "train_df['alis_top'] = (train_df[sites].astype(str).isin(alis_top_sites)==True).sum(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add features based on the session start time: hour, whether it's morning, day or night and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You code here\n",
    "-кол-во сайтов в сессии из ТОП-10 принадлежащих Элис\n",
    "-месяц начала сессии\n",
    "-год начала сессии\n",
    "-час н.с.\n",
    "-день недели н.с.\n",
    "-длительность сессии\n",
    "-средняя длительность сессии\n",
    "\n",
    "- час\n",
    "- месяц\n",
    "- день недели\n",
    "\n",
    "- утро (0/1)\n",
    "- ночь (0/1)\n",
    "- ГГГГММ\n",
    "\n",
    "\n",
    "сайт == слово \n",
    "row - предложение типо\n",
    "\n",
    "т.е индексы сайтов нужно склеить через пробел в одну строку для каждой сессии, и к этому уже tfidf применять?\n",
    "\n",
    "\n",
    "Я попробовал обратно замапить id-шники сайтов в URL, потом разбить на компоненты и сделать TF-IDF от получившихся слов. Но что-то это не помогло, хотя считало долго "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_session_day_night</th>\n",
       "      <th>start_session_morning</th>\n",
       "      <th>alis_top</th>\n",
       "      <th>start_session_15</th>\n",
       "      <th>start_session_16</th>\n",
       "      <th>start_session_18</th>\n",
       "      <th>start_session_year_14</th>\n",
       "      <th>start_session_year_13</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>start_session_hour_7</th>\n",
       "      <th>...</th>\n",
       "      <th>start_session_hour_21</th>\n",
       "      <th>start_session_hour_22</th>\n",
       "      <th>start_session_hour_23</th>\n",
       "      <th>start_session_day_of_the_week_0</th>\n",
       "      <th>start_session_day_of_the_week_1</th>\n",
       "      <th>start_session_day_of_the_week_2</th>\n",
       "      <th>start_session_day_of_the_week_3</th>\n",
       "      <th>start_session_day_of_the_week_4</th>\n",
       "      <th>start_session_day_of_the_week_5</th>\n",
       "      <th>start_session_day_of_the_week_6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            start_session_day_night  start_session_morning  alis_top  \\\n",
       "session_id                                                             \n",
       "21669                             0                      1         8   \n",
       "54843                             0                      1         6   \n",
       "77292                             0                      1         0   \n",
       "114021                            0                      1         0   \n",
       "146670                            0                      1         0   \n",
       "\n",
       "            start_session_15  start_session_16  start_session_18  \\\n",
       "session_id                                                         \n",
       "21669                      0                 0                 0   \n",
       "54843                      0                 0                 0   \n",
       "77292                      0                 0                 0   \n",
       "114021                     0                 0                 0   \n",
       "146670                     0                 0                 0   \n",
       "\n",
       "            start_session_year_14  start_session_year_13  is_weekend  \\\n",
       "session_id                                                             \n",
       "21669                       False                  False           1   \n",
       "54843                       False                  False           1   \n",
       "77292                       False                  False           1   \n",
       "114021                      False                  False           1   \n",
       "146670                      False                  False           1   \n",
       "\n",
       "            start_session_hour_7               ...                 \\\n",
       "session_id                                     ...                  \n",
       "21669                          0               ...                  \n",
       "54843                          0               ...                  \n",
       "77292                          0               ...                  \n",
       "114021                         0               ...                  \n",
       "146670                         0               ...                  \n",
       "\n",
       "            start_session_hour_21  start_session_hour_22  \\\n",
       "session_id                                                 \n",
       "21669                           0                      0   \n",
       "54843                           0                      0   \n",
       "77292                           0                      0   \n",
       "114021                          0                      0   \n",
       "146670                          0                      0   \n",
       "\n",
       "            start_session_hour_23  start_session_day_of_the_week_0  \\\n",
       "session_id                                                           \n",
       "21669                           0                                0   \n",
       "54843                           0                                0   \n",
       "77292                           0                                0   \n",
       "114021                          0                                0   \n",
       "146670                          0                                0   \n",
       "\n",
       "            start_session_day_of_the_week_1  start_session_day_of_the_week_2  \\\n",
       "session_id                                                                     \n",
       "21669                                     0                                0   \n",
       "54843                                     0                                0   \n",
       "77292                                     0                                0   \n",
       "114021                                    0                                0   \n",
       "146670                                    0                                0   \n",
       "\n",
       "            start_session_day_of_the_week_3  start_session_day_of_the_week_4  \\\n",
       "session_id                                                                     \n",
       "21669                                     0                                0   \n",
       "54843                                     0                                0   \n",
       "77292                                     0                                0   \n",
       "114021                                    0                                0   \n",
       "146670                                    0                                0   \n",
       "\n",
       "            start_session_day_of_the_week_5  start_session_day_of_the_week_6  \n",
       "session_id                                                                    \n",
       "21669                                     1                                0  \n",
       "54843                                     1                                0  \n",
       "77292                                     1                                0  \n",
       "114021                                    1                                0  \n",
       "146670                                    1                                0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.get_dummies(train_df[new_features], columns=['start_session_hour', \n",
    "                                        'start_session_day_of_the_week'])\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale this features and combine then with Tf-Idf based on sites (you'll need `scipy.sparse.hstack`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_data = scaler.fit_transform(train_data, y)\n",
    "train_full = hstack((csr_matrix(train_data), X), format='csr')\n",
    "\n",
    "#train_full[:100].todense().sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform cross-validation with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max auc_roc: {1: array([[0.48897507, 0.49008882, 0.49008878, 0.49008887, 0.49008878,\n",
      "        0.49009808, 0.49014991, 0.49047751, 0.48592213, 0.48592213,\n",
      "        0.48592213, 0.48592213, 0.48592213, 0.48592213, 0.48592213,\n",
      "        0.48592213, 0.48592213, 0.48592213, 0.48592213, 0.48592213],\n",
      "       [0.45571573, 0.45576496, 0.455765  , 0.45576513, 0.45576652,\n",
      "        0.45577162, 0.45582578, 0.45789981, 0.45824727, 0.45824727,\n",
      "        0.45824727, 0.45824727, 0.45824727, 0.45824727, 0.45824727,\n",
      "        0.45824727, 0.45824727, 0.45824727, 0.45824727, 0.45824727],\n",
      "       [0.48271171, 0.4828044 , 0.4828044 , 0.48280457, 0.48280791,\n",
      "        0.48280409, 0.48287315, 0.48520059, 0.4806091 , 0.4806091 ,\n",
      "        0.4806091 , 0.4806091 , 0.4806091 , 0.4806091 , 0.4806091 ,\n",
      "        0.4806091 , 0.4806091 , 0.4806091 , 0.4806091 , 0.4806091 ],\n",
      "       [0.47749826, 0.47251892, 0.47251892, 0.47251888, 0.47251953,\n",
      "        0.47250895, 0.47257528, 0.4743354 , 0.47623168, 0.47623168,\n",
      "        0.47623168, 0.47623168, 0.47623168, 0.47623168, 0.47623168,\n",
      "        0.47623168, 0.47623168, 0.47623168, 0.47623168, 0.47623168],\n",
      "       [0.49190312, 0.49185385, 0.49185393, 0.49185419, 0.49185389,\n",
      "        0.49187414, 0.4919249 , 0.49648259, 0.49290953, 0.49290953,\n",
      "        0.49290953, 0.49290953, 0.49290953, 0.49290953, 0.49290953,\n",
      "        0.49290953, 0.49290953, 0.49290953, 0.49290953, 0.49290953]])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "searchCV = LogisticRegressionCV(\n",
    "        Cs=list(np.power(10.0, np.arange(-10, 10)))\n",
    "        ,penalty='l2'\n",
    "        ,scoring='roc_auc'\n",
    "        ,cv=5\n",
    "        ,random_state=17\n",
    "        ,max_iter=10000\n",
    "        ,fit_intercept=True\n",
    "        ,tol=10\n",
    "    )\n",
    "searchCV.fit(train_full, y)\n",
    "print ('Max auc_roc:', searchCV.scores_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction for the test set and form a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = # You code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_submission_file(test_pred, \"assignment6_alice_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
